{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-28T14:15:11.355322Z",
     "start_time": "2025-11-28T14:15:11.288173Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the data, marking '?' as NaN and stripping initial spaces from categories\n",
    "df = pd.read_csv('adult_raw.csv', na_values='?', skipinitialspace=True)\n",
    "print(f\"Initial Dataset Shape: {df.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Dataset Shape: (32561, 15)\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T14:15:11.425262Z",
     "start_time": "2025-11-28T14:15:11.383507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define column types based on the final set to be used\n",
    "numerical_cols = ['age', 'fnlwgt', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']\n",
    "categorical_cols_to_check = ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country']\n",
    "\n",
    "# Impute numerical missing values with the mean (safety check)\n",
    "for col in numerical_cols:\n",
    "    if df[col].isnull().any():\n",
    "        df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "# Drop columns with missing categorical data and the redundant 'education' column\n",
    "cols_to_drop = [col for col in categorical_cols_to_check if df[col].isnull().any()]\n",
    "cols_to_drop.append('education')\n",
    "\n",
    "df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# Define the final lists for the preprocessor\n",
    "categorical_cols = [col for col in categorical_cols_to_check if col not in cols_to_drop]\n",
    "\n",
    "print(f\"Columns Dropped: {cols_to_drop}\")\n",
    "df.head()"
   ],
   "id": "56f18863f3c13e33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns Dropped: ['workclass', 'occupation', 'native.country', 'education']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   age  fnlwgt  education.num marital.status   relationship   race     sex  \\\n",
       "0   90   77053              9        Widowed  Not-in-family  White  Female   \n",
       "1   82  132870              9        Widowed  Not-in-family  White  Female   \n",
       "2   66  186061             10        Widowed      Unmarried  Black  Female   \n",
       "3   54  140359              4       Divorced      Unmarried  White  Female   \n",
       "4   41  264663             10      Separated      Own-child  White  Female   \n",
       "\n",
       "   capital.gain  capital.loss  hours.per.week income  \n",
       "0             0          4356              40  <=50K  \n",
       "1             0          4356              18  <=50K  \n",
       "2             0          4356              40  <=50K  \n",
       "3             0          3900              40  <=50K  \n",
       "4             0          3900              40  <=50K  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>77053</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>132870</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>186061</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>140359</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>264663</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T14:15:11.511443Z",
     "start_time": "2025-11-28T14:15:11.438872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = df.drop(columns=['income'])\n",
    "y = df['income']\n",
    "\n",
    "# Encode the target variable (y) to 0s and 1s\n",
    "y = y.replace({'<=50K': 0, '>50K': 1}).astype(int)\n",
    "\n",
    "# Split data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "print(f\"X_train shape: {X_train.shape}\")"
   ],
   "id": "ee9bd2284ecd3a6f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (26048, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gokul\\AppData\\Local\\Temp\\ipykernel_9292\\1657638314.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y = y.replace({'<=50K': 0, '>50K': 1}).astype(int)\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T14:15:11.716289Z",
     "start_time": "2025-11-28T14:15:11.543395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the transformers for ColumnTransformer\n",
    "numerical_transformer = StandardScaler() # Standardize numerical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore', drop='first') # One-Hot Encode categorical data\n",
    "\n",
    "# Combine transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Build the final Pipeline: Preprocessor + Model\n",
    "logreg_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data (Preprocessing and Training occur here)\n",
    "logreg_pipeline.fit(X_train, y_train)\n",
    "print(\"\\n✅ Preprocessing and Logistic Regression Model Training Complete!\")\n"
   ],
   "id": "c361362edd00d609",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Preprocessing and Logistic Regression Model Training Complete!\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T14:15:11.795628Z",
     "start_time": "2025-11-28T14:15:11.728349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assuming you have run the full preprocessing code previously,\n",
    "# we reuse the defined lists and the preprocessor object.\n",
    "\n",
    "# Extract the preprocessor from the final pipeline\n",
    "preprocessor = logreg_pipeline.named_steps['preprocessor']\n",
    "\n",
    "# 1. Transform the training data (X_train)\n",
    "X_train = preprocessor.transform(X_train)\n",
    "\n",
    "# 2. Transform the testing data (X_test)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"✅ Data transformation complete!\")\n",
    "print(f\"X_train_processed shape: {X_train.shape}\")\n",
    "print(f\"X_test_processed shape: {X_test.shape}\")"
   ],
   "id": "456f6bd003de023e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data transformation complete!\n",
      "X_train_processed shape: (26048, 22)\n",
      "X_test_processed shape: (6513, 22)\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T14:15:11.842746Z",
     "start_time": "2025-11-28T14:15:11.821662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Get feature names from the OneHotEncoder (for categorical columns)\n",
    "# The preprocessor's 'cat' step is the OneHotEncoder.\n",
    "feature_names_cat = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols).tolist()\n",
    "\n",
    "# 2. Combine all feature names\n",
    "# Remember the numerical columns are preserved\n",
    "final_feature_names = numerical_cols + feature_names_cat\n",
    "\n",
    "# 3. Convert the NumPy arrays back to pandas DataFrames\n",
    "X_train_df = pd.DataFrame(X_train, columns=final_feature_names)\n",
    "X_test_df = pd.DataFrame(X_test, columns=final_feature_names)\n",
    "\n",
    "# Add the target variable (y) back to the DataFrames\n",
    "X_train_df['income'] = y_train.reset_index(drop=True)\n",
    "X_test_df['income'] = y_test.reset_index(drop=True)\n",
    "\n",
    "print(f\"Total features created: {len(final_feature_names)}\")"
   ],
   "id": "6f892aad7af0b25a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features created: 22\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T14:15:12.463639Z",
     "start_time": "2025-11-28T14:15:11.944288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the processed training data\n",
    "X_train_df.to_csv('train.csv', index=False)\n",
    "\n",
    "# Save the processed testing data\n",
    "X_test_df.to_csv('test.csv', index=False)\n",
    "\n",
    "print(\"\\n--- Saving Complete ---\")\n",
    "print(\"Saved training features and target to: train.csv\")\n",
    "print(\"Saved testing features and target to: test.csv\")\n",
    "print(\"You can now load these CSV files directly for future model training.\")"
   ],
   "id": "45071824786da584",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Saving Complete ---\n",
      "Saved training features and target to: census_train_processed.csv\n",
      "Saved testing features and target to: census_test_processed.csv\n",
      "You can now load these CSV files directly for future model training.\n"
     ]
    }
   ],
   "execution_count": 38
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
